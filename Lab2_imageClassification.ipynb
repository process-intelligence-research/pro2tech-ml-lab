{"cells":[{"cell_type":"markdown","metadata":{"id":"O4UPdA07pO97"},"source":["# **case study**\n","\n","# Image classification with convolutional neural network in PyTorch\n","\n","Image classification is a classical and core task in computer vision, which has a large variety of practical applications. With the advent of deep learning, in combination with robust AI hardware and GPUs, outstanding performance has been achieved on image classification tasks. Thus, in this tutorial, we will use a convolutional neural network to do image classification using the PyTorch framework.\n","\n","**After this tutorial you will be able to:**\n","- Understand the training process of image classification\n","- Get the gist of the powerful performance of CNN\n","- Implement an easy-to-use CNN to do the image classification"]},{"cell_type":"markdown","metadata":{"id":"eSSPukUVBSOG"},"source":["## 1.1 - Python preparation\n","### Install packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0CThccehpNya","outputId":"d38077e1-63b5-4b81-88b7-5133cf991ea5","trusted":true},"outputs":[],"source":["# install dependencies\n","!pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n","# !pip install torch\n","!pip install matplotlib\n","!pip install sklearn"]},{"cell_type":"markdown","metadata":{"id":"zx4FzAmBBtIN"},"source":["### Import packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zXPkXQYKBb_l","trusted":true},"outputs":[],"source":["import numpy as np  # numerical calculations in python\n","import matplotlib.pyplot as plt  # plotting similar to matlab\n","import torch  # PyTorch: the general machine learning framework in Python\n","import torch.optim as optim  # contains optimizers for the backpropagation\n","import torch.nn as nn  # the artificial neural network module in PyTorch\n","import torch.nn.functional as F #\n","import torchvision  #Torchvision is a package in the PyTorch library containing computer-vision models, datasets, and image transformations.\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms \n","from sklearn.model_selection import train_test_split  # randomly splits a dataset"]},{"cell_type":"markdown","metadata":{"id":"foQS6OwUCmsX"},"source":["### Set the seed\n","To make our results reproducable, we need to set a so-called \"seed\". Machine Learning includes stochastic processes in the weight/bias initialization and the backpropagation. Also the random number generation which we will use for the dataset is a stochastic process. By setting a seed in the program we make sure that always the same random numbers are chosen. Otherwise, we would get different results everytime we run this script, which is not nice for teaching purposes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JilEFQlXByyT","trusted":true},"outputs":[],"source":["torch.manual_seed(0)\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{"id":"Rxr9_EmwCzcl"},"source":["## 1.2 - Prepare datasets\n","MNIST stands for Modified National Institute of Standards and Technology and is a database of 60,000 small square 28x28 pixel grayscale images. MNIST handwritten digits dataset is the most used for learning Image Recognition. It is labeled in the sense that each image of a handwritten digit has the corresponding numeral value attached to it. This helps our Algorithm/Neural Network to learn which image stands for which number (0-9) and to learn hidden patterns in human writing.\n","\n","Here we only use 5000 images from the original MNIST dataset because of the limited training time.\n","\n","**Download the dataset**\n","\n","*   Training dataset: 5000 images and 10 categories\n","*   Test dataset: 10000 image sand 10 categories\n","\n","Pytorch works with *Dataset*s and *DataLoader*s (more information [here](https://pytorch.org/docs/stable/data.html)) to feed minibatches to the model during training. Using the DataLoader allows for advanced training methods. Itâ€™s easy to create a dataset from the already created tensors. We print out one example data point, containing the input and output tensor."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZSaEhkWhNeOf","trusted":true},"outputs":[],"source":["#Normalize the data\n","transform=transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","    ])\n","\n","# Loading training dataset\n","trainset = datasets.MNIST('./', train=True, download=True,\n","                    transform=transform)\n","#Loading test dataset\n","testset = datasets.MNIST('./', train=False,\n","                    transform=transform)\n","\n","# Get subset of training dataset\n","#In total 5000 images \n","indices = np.arange(len(trainset))\n","train_indices, test_indices = train_test_split(indices, train_size=500*10, stratify=trainset.targets)\n","train_dataset = torch.utils.data.Subset(trainset, train_indices)\n","\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=50)\n","test_loader = torch.utils.data.DataLoader(testset, shuffle=False, batch_size=1000)\n"]},{"cell_type":"markdown","metadata":{"id":"cValhGoykMNi"},"source":["**Visualize the dataset 10 images from each classes**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":700},"id":"lp5k77ITFuIr","outputId":"257f9cef-ba63-4ec3-cc5b-af1c945b42d9","trusted":true},"outputs":[],"source":["def imshow(img):\n","    npimg = img.numpy()\n","    plt.figure(figsize=(12, 12))\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.yticks([18 + i*30 for i in range(len(classes))], classes, fontsize=15)\n","    plt.xticks([])\n","    plt.tick_params(length=0)\n","    plt.show()\n","\n","# get 10 training images of each class\n","classes = [0,1,2,3,4,5,6,7,8,9]\n","images = []\n","for class_ in classes:\n","    for image, label in trainset:\n","        if label == class_:\n","            images.append(image)\n","        if len(images) == (class_ + 1)*10:\n","            break\n","\n","# show images\n","imshow(torchvision.utils.make_grid(images, nrow=10, padding=2))"]},{"cell_type":"markdown","metadata":{"id":"TFM8ety9mel_"},"source":["## 1.3 - Set up a convolutional neural network\n","The general convolutional neural networks contain convolutional layers, pooling layers and fully-connected layers. PyTorch provides the framework for building CNNs. The *nn.Module* is the standard class for CNN in PyTorch. The abbreviation *nn* stands for the neural network. We build a child class of it where we specify our desired model architecture. Pytorch uses a base model object and adds the layers and activations as other objects in a sequential manner. The first layer must get input dimensions matching the data, whereas the following can deduce their input size from the previous layer. The output layer then must match the dimension of the target values. **For the greyscale images the input channel is 1, and for RGB images the input channels are 3.** Each CNN class needs a *forward* function which defines, how a signal propagates through the network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4KLUWk0nsFIP","trusted":true},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        #Input layer: convolutional layer\n","        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1)\n","        self.relu1 = nn.ReLU(inplace = True)\n","        #Hidden layer: convolutional layer\n","        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1)\n","        self.relu2 = nn.ReLU(inplace = True)\n","        #Pooling layer\n","        self.max_pool = nn.MaxPool2d(kernel_size = 2)\n","        #Fully-connetced layer \n","        self.fc1 = nn.Linear(in_features = 9216, out_features = 128)\n","        self.relu3 = nn.ReLU(inplace = True)\n","        self.fc2 = nn.Linear(in_features = 128, out_features = 10)\n","\n","    def forward(self, x):\n","        # feed forward path\n","        result_first_conv = self.conv1(x)\n","        result_first_relu = self.relu1(result_first_conv)\n","        result_second_conv = self.conv2(result_first_relu)\n","        result_second_relu = self.relu2(result_second_conv)\n","        result_pooling = self.max_pool(result_second_relu)\n","        x = torch.flatten(result_pooling, 1)\n","        x = self.fc1(x)\n","        x = self.relu3(x)\n","        x = self.fc2(x)\n","        output = F.log_softmax(x, dim=1)\n","        return output, result_first_conv,result_second_conv, result_first_relu,result_second_relu,result_pooling "]},{"cell_type":"markdown","metadata":{"id":"1gceY2-JyBhH"},"source":["## 1.4 - Train CNN\n","Now the fun begins. We put the dataset and CNN architecture together to \"train\" our CNN.\n","\n","We use the training data to train our neural network. This process is nothing else then optimizing the weights and biases in our network. Before starting the training process, we need to define a few things:\n","- *optimizer*: Here we use *AdaDelta*. AdaDelta is a stochastic optimization technique that allows for a per-dimension learning rate method for stochastic gradient descent. With the optimizer, we also need to define the learning rate *lr*. It determines how fast we adopt the weights and biases during the training. If it is too high, the learning becomes unstable and the loss increases. If it is too low, we need too many epochs and we do not reach satisfying precision.\n","- *loss function*: This is the objective of our training/optimization. Here we use cross-entropy loss for the classification problem.\n","- *epochs*: How often do we want to repeat the training with our dataset?\n","\n","Optimizing these parameters is called hyerparameter tuning."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDbT7uQMqcv6","outputId":"63ea68c8-ce10-4667-fd5b-6ad6e0b66858","trusted":true},"outputs":[],"source":["model = Net()# create neural network\n","optimizer = optim.Adadelta(model.parameters(), lr=1)   # choose optimizer and learning rate\n","loss_function = nn.CrossEntropyLoss() # define loss function\n","epochs = 1 # set number of epochs\n","model"]},{"cell_type":"markdown","metadata":{"id":"_sg1E2YK9xdM"},"source":["This is the main part of using a CNN: the actual \"training\". We give input to the network and see how the output differs from our expected output. The difference is used to calculate the loss. Then we update the weights and biases such that the loss will be smaller in the next epoch."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GMmN-0Jzyne9","trusted":true},"outputs":[],"source":["\n","def train(num_epochs, net, trainloader, optimizer, loss_function):\n","    \n","    net.train()\n","        \n","    # Train the model\n","    for epoch in range(num_epochs):\n","\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            \n","  \n","            # clear gradients for this training step   \n","            optimizer.zero_grad()  \n","\n","            # forward pass: prediction y based on input x\n","            output,_,_,_,_,_ = net(data)\n","\n","            # compare true y and predicted y to get the loss             \n","            loss = loss_function(output, target)\n","                     \n","            \n","            # backpropagation, compute gradients \n","            loss.backward()  \n","      \n","            # apply gradients             \n","            optimizer.step() \n","          \n","            if (batch_idx+1) % 10 == 0:\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch+1, batch_idx * len(data), len(train_loader.dataset),\n","                    100. * batch_idx / len(train_loader), loss.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r0a4qbTozf7e","outputId":"78867d15-b7d3-4616-d960-bcd7a2eaea77","trusted":true},"outputs":[],"source":["train(epochs, model, train_loader, optimizer,loss_function)"]},{"cell_type":"markdown","metadata":{"id":"AQ__M7R0-9r6"},"source":["## 1.5 - Evaluate CNN\n","\n","**Accuracy of test dataset**\n","\n","First, we use a test dataset to evaluate our trained CNN and to calculate the overall accuracy for all classes."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"laWQ8qTjLLHl","outputId":"54996d1b-487e-4303-b92b-484e545c7fde","trusted":true},"outputs":[],"source":["def test(model, test_loader):\n","    model.eval()\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            output,_,_,_,_,_ = model(data)\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","\n","    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","         correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","test(model, test_loader)"]},{"cell_type":"markdown","metadata":{"id":"ksmaiFaBBYhw"},"source":["**Intermediate results**\n","\n","How did our CNN model process this image? What actually happens within the CNN model? To help you understand the whole process, let's discover the intermediate results in the neural network.\n","\n","First, we select one image as an example: \n","\n","**Choose a random image $\\in[0, 9999]$**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["choose_one_image = 1 #[0,9999]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":252},"id":"qMhkkps7BX_5","outputId":"afeddcdb-95cc-40ca-e5f5-ee24ad898dc3","trusted":true},"outputs":[],"source":["#plot image\n","plt.imshow(testset[choose_one_image][0].reshape(28,28),cmap='gray')\n","plt.xticks([])\n","plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"fcxtDQtBs4Fm"},"source":["Next, we plot **first six channels** after **first convolutional layer, second convolutional layer and max pooling layer**."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":980},"id":"OrP1HtCedNzz","outputId":"b11ff1c1-b691-4c63-c63b-dbbc1da9720c","trusted":true},"outputs":[],"source":["def plot_image(image,model):\n","    image_list = [ ]\n","    _, first_conv, second_conv, first_relu, second_relu, pooling = model(image.reshape(1,1,28,28))\n","    for layer in [first_relu, second_relu, pooling]:\n","        for number in range(6):\n","            image_example = layer[0][number].reshape(layer.shape[-1],layer.shape[-1])\n","            pad_number = int((28 - image_example.shape[-1])/2)\n","            pad = nn.ConstantPad2d(padding=(pad_number, pad_number, pad_number, pad_number), value=1)\n","            image_after_padding = pad(image_example)\n","            # print(image_after_padding.shape)\n","            image_list.append(image_after_padding.reshape(1,28,28))\n","\n","    img = torchvision.utils.make_grid(image_list, nrow=6, padding=2)\n","    npimg = img.detach().numpy()\n","    plt.figure(figsize=(20, 20))\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","    plt.yticks([15, 45, 75], ['Conv1', 'Conv2',  'Max Pooling'], fontsize=15)\n","    plt.xticks([])\n","    plt.tick_params(length=0)\n","    plt.show()\n","    return image_list\n","image_list = plot_image(testset[choose_one_image][0],model)\n"]},{"cell_type":"markdown","metadata":{"id":"RsEGzdxgu1cZ"},"source":["**Discussion**\n","\n","We can see that in the early stage of convolutional layer, CNN uses different filters to get the simple features such as edges and corners. More complex and abstract patterns appear with further concolutional layers. And the pooling layer helps to reduce the spatial dimension and keep the most important features.   "]},{"cell_type":"markdown","metadata":{"id":"3Neo5-CzxeqC"},"source":["## 1.6 - Conclusion\n","In the second lab we demonstrated how to use a CNN for image classification. We introduced how to set up a CNN for image classification and how to evaluate the result. We also discussed how the CNN process our images within the model.\n","\n","We hope you enjoyed it!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Lab2-imageClassification.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
